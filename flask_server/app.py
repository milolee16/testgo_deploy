# ml-flask/app.py
from flask import Flask, request, jsonify
from flask_cors import CORS
from textblob import TextBlob
from datetime import datetime
import requests
app = Flask(__name__)
CORS(app)  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (ê°œë°œìš©)

@app.route('/ml', methods=['get'])
def predict():
    result = {'con' : 'connected'}
    # data = request.json  # í´ë¼ì´ì–¸íŠ¸ì—ì„œ JSON ë³´ë‚´ë©´ ë°›ìŒ
    # ì—¬ê¸°ì„œ ML ëª¨ë¸ ì²˜ë¦¬
    # ì˜ˆì‹œ: ê·¸ëƒ¥ ë°›ì€ ë°ì´í„° ê·¸ëŒ€ë¡œ ë°˜í™˜
    # result = {'input': data, 'prediction': 'dummy_result'}
    return jsonify(result), 200

@app.route('/ml/test1', methods=['post'])
def test1():
    data = request.json
    texts = data.get("texts", [])
    results = []
    for text in texts:
        polarity = TextBlob(text).sentiment.polarity
        sentiment = "Positive" if polarity >= 0 else "Negative"
        results.append({"text": text, "sentiment": sentiment, "score": polarity})
    return jsonify(results), 200


OLLAMA_API_URL = "http://192.168.0.22:11434/api/generate"
OLLAMA_MODEL = "llama3"


@app.route("/ml/schedule", methods=["POST"])
def schedule():
    messages = request.get_json()
    print("ğŸ“¦ ë°›ì€ ë°ì´í„°:", messages)

    # ë©”ì‹œì§€ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ë°œí™” ìˆœì„œ ê·¸ëŒ€ë¡œ)
    conversation = "\n".join([f"{m['sender']} : {m['message']}" for m in messages])
    # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ (ì˜ˆ: "ì´ë²ˆ ì£¼ ì£¼ë§" ê°™ì€ í‘œí˜„ íŒŒì‹±ìš©)
    today = datetime.now().strftime("%Y-%m-%d")
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
í•œê¸€ë¡œ ëŒ€ë‹µ í•´ì£¼ì„¸ìš”.  
ë‹¹ì‹ ì€ ì¼ì • ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ë‘ ì‚¬ëŒì´ ë‚˜ëˆˆ ëŒ€í™”ì…ë‹ˆë‹¤. ëŒ€í™”ì—ì„œ ì•½ì†ì´ë‚˜ ì¼ì •ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆë‹¤ë©´ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

ì˜¤ëŠ˜ ë‚ ì§œëŠ” {today}ì…ë‹ˆë‹¤.
    JSON í˜•ì‹:
{{
  "is_schedule": true/false,
  "title": "",
  "start_time": "YYYY-MM-DDTHH:MM:SS",
  "end_time": "YYYY-MM-DDTHH:MM:SS",
  "all_day": 0 or 1,
  "location": "",
  "description": "",
  "recurrence_rule": null
}}

ê·œì¹™:
- ë‚ ì§œëŠ” ê°€ëŠ¥í•œ ì •í™•íˆ ISO 8601 í˜•ì‹ìœ¼ë¡œ ì‘ì„± (YYYY-MM-DDTHH:MM:SS).
- 'ì´ë²ˆ ì£¼ ì£¼ë§'ê³¼ ê°™ì€ í‘œí˜„ì€ ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•´ì„.
- ì‹œê°„ì´ ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ all_day = 1ë¡œ ì„¤ì •í•˜ê³  start_time, end_timeì€ ë‚ ì§œë§Œ ì§€ì •.
- locationì´ ì—†ìœ¼ë©´ nullë¡œ ì„¤ì •.
- ë°˜ë³µë˜ëŠ” ì¼ì •ì´ ì•„ë‹ˆë¼ë©´ recurrence_rule = null.
- ëŒ€í™”ì— ì¼ì •ì´ ì—†ìœ¼ë©´ is_schedule = falseë¡œ ì„¤ì •í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” null.
- titleì€ ì¼ì •ì˜ í•µì‹¬ ìš”ì•½ (ì˜ˆ: "ì ì‹¬ ì•½ì†", "íšŒì˜").
- descriptionì€ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ í¬í•¨ (ì˜ˆ: "í™ëŒ€ì—ì„œ ì ì‹¬ ë¨¹ê³  ì¹´í˜ ê°€ê¸°").

ëŒ€í™”:
\"\"\"  
{conversation}
\"\"\"
"""
    # Ollama ìš”ì²­
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt.strip(),
        "stream": False
    }
    response = requests.post(OLLAMA_API_URL, json=payload)
    result = response.json()
    print(response.text)
    # ê²°ê³¼ ë¦¬í„´
    return jsonify({
        "raw_response": result.get("response", "").strip()
    })
if __name__ == '__main__':
    # ê°œë°œìš© ì„œë²„
    app.run(host='0.0.0.0', port=5000, debug=True)